{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAlex data retrieved:\n",
      "  ProjectID    ProjectStatus ProjectTitle                                       ProjectRDC ProjectStartYear ProjectEndYear ProjectPI          OutputTitle                                        OutputBiblio                                       OutputType OutputStatus OutputVenue  OutputYear OutputMonth OutputVolume OutputNumber OutputPages DOI                                                Authors                                            Abstract                                          \n",
      "0  W2049165791  None                               Research Diagnostic Criteria  None       None             None           Robert L. Spitzer                       Research Diagnostic Criteria  {'volume': '35', 'issue': '6', 'first_page': '...  article    None         None        1978        None        35            6             773-773   https://doi.org/10.1001/archpsyc.1978.01770300...                                  Robert L. Spitzer  • A crucial problem in psychiatry, affecting c...\n",
      "1  W2051239218  None          Projections of Primary and Revision Hip and Kn...  None       None             None             Steven M. Kurtz  Projections of Primary and Revision Hip and Kn...  {'volume': '89', 'issue': '4', 'first_page': '...  article    None         None        2007        None        89            4             780-785                https://doi.org/10.2106/jbjs.f.00222  Steven M. Kurtz, Kevin Ong, Edmund Lau, Fionna...  Over the past decade, there has been an increa...\n",
      "2  W2011545725  None          Diagnostic Criteria for Temporomandibular Diso...  None       None             None              Eric Schiffman  Diagnostic Criteria for Temporomandibular Diso...  {'volume': '28', 'issue': '1', 'first_page': '...  article    None         None        2014        None        28            1                6-27                   https://doi.org/10.11607/jop.1151  Eric Schiffman, Richard Ohrbach, Edmond L. Tru...  The original Research Diagnostic Criteria for ...\n",
      "3  W2153019931  None          Racial and Ethnic Stratification in Educationa...  None       None             None                   Grace Kao  Racial and Ethnic Stratification in Educationa...  {'volume': '29', 'issue': '1', 'first_page': '...  article    None         None        2003        None        29            1             417-442   https://doi.org/10.1146/annurev.soc.29.010202....                       Grace Kao, Jennifer Thompson  ▪ Abstract Understanding racial, ethnic, and i...\n",
      "4  W2109154308  None          CHARMM36 all-atom additive protein force field...  None       None             None                  Jing Huang  CHARMM36 all-atom additive protein force field...  {'volume': '34', 'issue': '25', 'first_page': ...  article    None         None        2013        None        34           25           2135-2145                   https://doi.org/10.1002/jcc.23354                 Jing Huang, Alexander D. MacKerell  Protein structure and dynamics can be characte...\n",
      "Retrieved 100 CORE outputs for offset 0.\n",
      "Retrieved 100 CORE outputs for offset 100.\n",
      "Retrieved 100 CORE outputs for offset 200.\n",
      "Total CORE outputs retrieved: 300\n",
      "CORE API data retrieved:\n",
      "   ProjectID ProjectStatus ProjectTitle                                       ProjectRDC ProjectStartYear ProjectEndYear ProjectPI       OutputTitle                                        OutputBiblio OutputType OutputStatus OutputVenue OutputYear OutputMonth OutputVolume OutputNumber OutputPages DOI Authors                                          Abstract                                          \n",
      "0  219376570  None          Disclosure Limitation and Confidentiality Prot...  None       None             None           Abowd, John M.  Disclosure Limitation and Confidentiality Prot...  None         None       None         None        None       None        None         None         None            Abowd, John M., Schmutte, Ian M, Vilhuber, Lars  Confidentiality protection for linked administ...\n",
      "1  127599733  None          Proceedings from the Synthetic LBD Internation...  None       None             None           Vilhuber, Lars  Proceedings from the Synthetic LBD Internation...  None         None       None         None        None       None        None         None         None              Vilhuber, Lars, Kinney, Saki, Schmutte, Ian M  On May 9, 2017, we hosted a seminar to discuss...\n",
      "2   83602625  None          Center for Economic Studies and Research Data ...  None       None             None                     None  Center for Economic Studies and Research Data ...  None         None       None         None        None       None        None         None         None                                                       None  Many individuals within and outside the Census...\n",
      "3  127599735  None          Making Confidential Data Part of Reproducible ...  None       None             None           Vilhuber, Lars  Making Confidential Data Part of Reproducible ...  None         None       None         None        None       None        None         None         None                               Vilhuber, Lars, Lagoze, Carl                                                   \n",
      "4   79053705  None          Confidentiality Protection and Physical Safegu...  None       None             None           Vilhuber, Lars  Confidentiality Protection and Physical Safegu...  None         None       None         None        None       None        None         None         None                                             Vilhuber, Lars  Presentation given at the joint seminar of the...\n",
      "Combined API data:\n",
      "  ProjectID    ProjectStatus ProjectTitle                                       ProjectRDC ProjectStartYear ProjectEndYear ProjectPI          OutputTitle                                        OutputBiblio                                       OutputType OutputStatus OutputVenue OutputYear OutputMonth OutputVolume OutputNumber OutputPages DOI                                                Authors                                            Abstract                                          \n",
      "0  W2049165791  None                               Research Diagnostic Criteria  None       None             None           Robert L. Spitzer                       Research Diagnostic Criteria  {'volume': '35', 'issue': '6', 'first_page': '...  article    None         None        1978       None        35            6             773-773   https://doi.org/10.1001/archpsyc.1978.01770300...                                  Robert L. Spitzer  • A crucial problem in psychiatry, affecting c...\n",
      "1  W2051239218  None          Projections of Primary and Revision Hip and Kn...  None       None             None             Steven M. Kurtz  Projections of Primary and Revision Hip and Kn...  {'volume': '89', 'issue': '4', 'first_page': '...  article    None         None        2007       None        89            4             780-785                https://doi.org/10.2106/jbjs.f.00222  Steven M. Kurtz, Kevin Ong, Edmund Lau, Fionna...  Over the past decade, there has been an increa...\n",
      "2  W2011545725  None          Diagnostic Criteria for Temporomandibular Diso...  None       None             None              Eric Schiffman  Diagnostic Criteria for Temporomandibular Diso...  {'volume': '28', 'issue': '1', 'first_page': '...  article    None         None        2014       None        28            1                6-27                   https://doi.org/10.11607/jop.1151  Eric Schiffman, Richard Ohrbach, Edmond L. Tru...  The original Research Diagnostic Criteria for ...\n",
      "3  W2153019931  None          Racial and Ethnic Stratification in Educationa...  None       None             None                   Grace Kao  Racial and Ethnic Stratification in Educationa...  {'volume': '29', 'issue': '1', 'first_page': '...  article    None         None        2003       None        29            1             417-442   https://doi.org/10.1146/annurev.soc.29.010202....                       Grace Kao, Jennifer Thompson  ▪ Abstract Understanding racial, ethnic, and i...\n",
      "4  W2109154308  None          CHARMM36 all-atom additive protein force field...  None       None             None                  Jing Huang  CHARMM36 all-atom additive protein force field...  {'volume': '34', 'issue': '25', 'first_page': ...  article    None         None        2013       None        34           25           2135-2145                   https://doi.org/10.1002/jcc.23354                 Jing Huang, Alexander D. MacKerell  Protein structure and dynamics can be characte...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liamr\\AppData\\Local\\Temp\\ipykernel_24600\\555980874.py:221: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  merged_df = pd.concat([existing_df, api_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data saved to Updated_ResearchOutputs.xlsx\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "\n",
    "#########################\n",
    "# Final Schema Columns\n",
    "#########################\n",
    "FINAL_COLUMNS = ['ProjectID', 'ProjectStatus', 'ProjectTitle', 'ProjectRDC', \n",
    "                 'ProjectStartYear', 'ProjectEndYear', 'ProjectPI', 'OutputTitle', \n",
    "                 'OutputBiblio', 'OutputType', 'OutputStatus', 'OutputVenue', \n",
    "                 'OutputYear', 'OutputMonth', 'OutputVolume', 'OutputNumber', \n",
    "                 'OutputPages', 'DOI', 'Authors', 'Abstract']\n",
    "\n",
    "#########################\n",
    "# OpenAlex API Functions\n",
    "#########################\n",
    "def reconstruct_abstract(abstract_dict):\n",
    "    \"\"\"Reconstructs an abstract from OpenAlex's abstract_inverted_index format.\"\"\"\n",
    "    if not abstract_dict:\n",
    "        return None\n",
    "    word_positions = [(pos, word) for word, positions in abstract_dict.items() for pos in positions]\n",
    "    sorted_words = sorted(word_positions, key=lambda x: x[0])\n",
    "    return \" \".join(word for _, word in sorted_words)\n",
    "\n",
    "def fetch_openalex_data(keywords, per_page=50):\n",
    "    \"\"\"\n",
    "    Fetches data from the OpenAlex API based on the provided keywords.\n",
    "    \n",
    "    Returns a DataFrame with the final schema.\n",
    "    \"\"\"\n",
    "    url = f\"https://api.openalex.org/works?filter=abstract.search:{keywords}&per_page={per_page}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        results = []\n",
    "        for work in data.get(\"results\", []):\n",
    "            reconstructed_abs = reconstruct_abstract(work.get(\"abstract_inverted_index\", {}))\n",
    "            full_project_id = work.get(\"id\", None)\n",
    "            project_id = re.search(r'[^/]+$', full_project_id).group() if full_project_id else None\n",
    "            results.append({\n",
    "                \"ProjectID\": project_id,\n",
    "                \"ProjectStatus\": work.get(\"status\", None),\n",
    "                \"ProjectTitle\": work.get(\"title\", None),\n",
    "                \"ProjectRDC\": work.get(\"rdc\", None),\n",
    "                \"ProjectStartYear\": work.get(\"start_year\", None),\n",
    "                \"ProjectEndYear\": work.get(\"end_year\", None),\n",
    "                \"ProjectPI\": work.get(\"authorships\", [{}])[0].get(\"author\", {}).get(\"display_name\", None) if work.get(\"authorships\") else None,\n",
    "                \"OutputTitle\": work.get(\"title\", None),\n",
    "                \"OutputBiblio\": work.get(\"biblio\", None),\n",
    "                \"OutputType\": work.get(\"type\", None),\n",
    "                \"OutputStatus\": work.get(\"status\", None),\n",
    "                \"OutputVenue\": work.get(\"host_venue\", {}).get(\"display_name\", None),\n",
    "                \"OutputYear\": work.get(\"publication_year\", None),\n",
    "                \"OutputMonth\": work.get(\"publication_month\", None),\n",
    "                \"OutputVolume\": work.get(\"biblio\", {}).get(\"volume\", None),\n",
    "                \"OutputNumber\": work.get(\"biblio\", {}).get(\"issue\", None),\n",
    "                \"OutputPages\": (work.get(\"biblio\", {}).get(\"first_page\", None) + \"-\" + work.get(\"biblio\", {}).get(\"last_page\", None)) if work.get(\"biblio\", {}).get(\"first_page\") else None,\n",
    "                \"DOI\": work.get(\"doi\", None),\n",
    "                \"Authors\": \", \".join([author['author']['display_name'] for author in work.get(\"authorships\", [])]) if work.get(\"authorships\") else None,\n",
    "                \"Abstract\": reconstructed_abs\n",
    "            })\n",
    "        return pd.DataFrame(results, columns=FINAL_COLUMNS)\n",
    "    else:\n",
    "        print(f\"OpenAlex API Request Failed: {response.status_code}\")\n",
    "        return pd.DataFrame(columns=FINAL_COLUMNS)\n",
    "\n",
    "#########################\n",
    "# CORE API Functions\n",
    "#########################\n",
    "def get_authors_str(authors_list):\n",
    "    \"\"\"Converts a list of authors (dicts or strings) to a comma-separated string.\"\"\"\n",
    "    names = []\n",
    "    for author in authors_list:\n",
    "        if isinstance(author, dict):\n",
    "            name = author.get(\"name\", None)\n",
    "            if name:\n",
    "                names.append(name)\n",
    "        else:\n",
    "            names.append(str(author))\n",
    "    return \", \".join(names) if names else None\n",
    "\n",
    "def fetch_core_data(keywords, limit=100, offset=0, api_key=\"uQXVRMa9IpkqghWnoxL2tm3CUj8dHr4F\"):\n",
    "    \"\"\"\n",
    "    Fetches a batch of CORE API outputs based on the provided keywords.\n",
    "    Implements a retry mechanism for HTTP 429 errors.\n",
    "    \n",
    "    Returns a DataFrame with the final schema.\n",
    "    \"\"\"\n",
    "    if isinstance(keywords, list):\n",
    "        query = \" OR \".join([f'fullText:\"{kw}\"' for kw in keywords])\n",
    "    else:\n",
    "        query = f'fullText:\"{keywords}\"'\n",
    "    \n",
    "    url = \"https://api.core.ac.uk/v3/search/outputs\"\n",
    "    headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "    params = {\"q\": query, \"limit\": limit, \"offset\": offset}\n",
    "    \n",
    "    max_retries = 5\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        if response.status_code == 200:\n",
    "            break\n",
    "        elif response.status_code == 429:\n",
    "            print(f\"CORE API Error 429 at offset {offset}. Retrying in 5 seconds (attempt {retries+1})...\")\n",
    "            time.sleep(5)\n",
    "            retries += 1\n",
    "        else:\n",
    "            print(f\"CORE API Error {response.status_code}: {response.text}\")\n",
    "            return pd.DataFrame(columns=FINAL_COLUMNS)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to retrieve CORE data for offset {offset} after {max_retries} attempts.\")\n",
    "        return pd.DataFrame(columns=FINAL_COLUMNS)\n",
    "    \n",
    "    data = response.json()\n",
    "    results = data.get(\"results\", [])\n",
    "    processed_results = []\n",
    "    for item in results:\n",
    "        project_id = item.get(\"id\", None)\n",
    "        project_title = item.get(\"title\", None)\n",
    "        authors_list = item.get(\"authors\", [])\n",
    "        authors_str = get_authors_str(authors_list)\n",
    "        if authors_list:\n",
    "            project_pi = authors_list[0].get(\"name\", None) if isinstance(authors_list[0], dict) else authors_list[0]\n",
    "        else:\n",
    "            project_pi = None\n",
    "        \n",
    "        # Attempt to get publication year\n",
    "        year_published = item.get(\"year_published\", None)\n",
    "        if not year_published or year_published == \"\":\n",
    "            published_date = item.get(\"published_date\", \"\")\n",
    "            if published_date and \"-\" in published_date:\n",
    "                output_year = published_date.split(\"-\")[0]\n",
    "            else:\n",
    "                output_year = None\n",
    "        else:\n",
    "            output_year = year_published\n",
    "        \n",
    "        doi = item.get(\"doi\", None)\n",
    "        abstract = item.get(\"abstract\", None)\n",
    "        \n",
    "        # For OutputBiblio, we use the download URL if available.\n",
    "        output_biblio = item.get(\"download_url\", None)\n",
    "        # For OutputType, use document_type.\n",
    "        output_type = item.get(\"document_type\", None)\n",
    "        # For OutputVenue, try to extract publisher name from the publisher field.\n",
    "        publisher_info = item.get(\"publisher\", {})\n",
    "        if isinstance(publisher_info, dict):\n",
    "            output_venue = publisher_info.get(\"name\", None)\n",
    "        else:\n",
    "            output_venue = None\n",
    "        \n",
    "        processed_results.append({\n",
    "            \"ProjectID\": project_id,\n",
    "            \"ProjectStatus\": None,\n",
    "            \"ProjectTitle\": project_title,\n",
    "            \"ProjectRDC\": None,\n",
    "            \"ProjectStartYear\": None,\n",
    "            \"ProjectEndYear\": None,\n",
    "            \"ProjectPI\": project_pi,\n",
    "            \"OutputTitle\": project_title,  # Use title as output title\n",
    "            \"OutputBiblio\": output_biblio,\n",
    "            \"OutputType\": output_type,\n",
    "            \"OutputStatus\": None,\n",
    "            \"OutputVenue\": output_venue,\n",
    "            \"OutputYear\": output_year,\n",
    "            \"OutputMonth\": None,\n",
    "            \"OutputVolume\": None,\n",
    "            \"OutputNumber\": None,\n",
    "            \"OutputPages\": None,\n",
    "            \"DOI\": doi,\n",
    "            \"Authors\": authors_str,\n",
    "            \"Abstract\": abstract\n",
    "        })\n",
    "    print(f\"Retrieved {len(processed_results)} CORE outputs for offset {offset}.\")\n",
    "    return pd.DataFrame(processed_results, columns=FINAL_COLUMNS)\n",
    "\n",
    "def fetch_core_data_all(keywords, total_results=300, batch_size=100, api_key=\"uQXVRMa9IpkqghWnoxL2tm3CUj8dHr4F\"):\n",
    "    \"\"\"\n",
    "    Retrieves CORE API outputs in batches and combines them into a single DataFrame.\n",
    "    \"\"\"\n",
    "    all_dfs = []\n",
    "    for offset in range(0, total_results, batch_size):\n",
    "        df_batch = fetch_core_data(keywords, limit=batch_size, offset=offset, api_key=api_key)\n",
    "        if df_batch.empty:\n",
    "            break\n",
    "        all_dfs.append(df_batch)\n",
    "        time.sleep(1)\n",
    "    if all_dfs:\n",
    "        final_df = pd.concat(all_dfs, ignore_index=True)\n",
    "        print(f\"Total CORE outputs retrieved: {len(final_df)}\")\n",
    "        return final_df\n",
    "    else:\n",
    "        print(\"No CORE outputs retrieved.\")\n",
    "        return pd.DataFrame(columns=FINAL_COLUMNS)\n",
    "\n",
    "#########################\n",
    "# Merge Functions\n",
    "#########################\n",
    "def merge_api_data(openalex_df, core_df):\n",
    "    \"\"\"\n",
    "    Merges OpenAlex and CORE API data (both in the final schema) into a single DataFrame.\n",
    "    \"\"\"\n",
    "    combined_df = pd.concat([openalex_df, core_df], ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "def merge_with_existing(existing_file, api_df, output_file):\n",
    "    \"\"\"\n",
    "    Merges existing ResearchOutputs Excel data with the new API data and saves the result.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        existing_df = pd.read_excel(existing_file)\n",
    "        existing_df = existing_df.reindex(columns=FINAL_COLUMNS)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Existing Excel file not found. Using empty DataFrame.\")\n",
    "        existing_df = pd.DataFrame(columns=FINAL_COLUMNS)\n",
    "    \n",
    "    merged_df = pd.concat([existing_df, api_df], ignore_index=True)\n",
    "    merged_df.to_excel(output_file, index=False)\n",
    "    print(f\"Merged data saved to {output_file}\")\n",
    "    return merged_df\n",
    "\n",
    "#########################\n",
    "# Main Execution Block\n",
    "#########################\n",
    "if __name__ == \"__main__\":\n",
    "    # Define keywords for API searches.\n",
    "    openalex_keywords = \"FSRDC|Census|IRS|BEA|RDC|confidentiality review|U.S. Census Bureau|Census Bureau|Bureau of Economic Analysis|[RDC]\"\n",
    "    core_keywords = [\"FSRDC\", \"Census\", \"BEA\", \"RDC\", \"U.S. Census Bureau\", \"Bureau of Economic Analysis\"]\n",
    "    \n",
    "    # Fetch data from OpenAlex.\n",
    "    openalex_df = fetch_openalex_data(openalex_keywords, per_page=50)\n",
    "    print(\"OpenAlex data retrieved:\")\n",
    "    print(openalex_df.head())\n",
    "    \n",
    "    # Fetch data from CORE API (using total_results=300 to avoid infinite retries).\n",
    "    core_df = fetch_core_data_all(core_keywords, total_results=300, batch_size=100, \n",
    "                                  api_key=\"uQXVRMa9IpkqghWnoxL2tm3CUj8dHr4F\")\n",
    "    print(\"CORE API data retrieved:\")\n",
    "    print(core_df.head())\n",
    "    \n",
    "    # Merge the API outputs.\n",
    "    combined_api_df = merge_api_data(openalex_df, core_df)\n",
    "    print(\"Combined API data:\")\n",
    "    print(combined_api_df.head())\n",
    "    \n",
    "    # Merge with existing ResearchOutputs Excel data.\n",
    "    merged_df = merge_with_existing(\"ResearchOutputs.xlsx\", combined_api_df, \"Updated_ResearchOutputs.xlsx\")\n",
    "    \n",
    "    # Optionally, also save to CSV.\n",
    "    merged_df.to_csv(\"Updated_ResearchOutputs.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
